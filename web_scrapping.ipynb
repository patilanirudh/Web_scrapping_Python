{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Basics of web scrapping using BeautifulSoup..!"
      ],
      "metadata": {
        "id": "S-BfSrG-QhJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOs55Od5j0qq",
        "outputId": "8cdbed8e-268d-4744-8a03-b79b35ce46de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "# ! pip install requests\n",
        "# ! pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "my_url = 'https://www.bikewale.com/best-bikes-in-india/'\n",
        "\n",
        "# opening url and grabbing the web page\n",
        "uClient = urlopen(my_url)\n",
        "page_html = uClient.read()\n",
        "uClient.close()\n",
        "\n",
        "# html parsing\n",
        "page_soup = soup(page_html, 'html.parser')\n",
        "\n",
        "# grabbing all containers with class name = item-container\n",
        "# containers = page_soup.findAll('div', {'class':'o-fzoHFO o-fzoHCA o-fzoHBq o-fzpilm o-brXWGL'})\n",
        "containers = page_soup.findAll('li', {'class':'o-fznJzb o-fHmpzP'})\n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "for container in containers:\n",
        "    # brand = container.div.div.a.img['title']\n",
        "    title_container = container.findAll('span', {'class':'o-eZTujG o-bkmzIL o-eqqVmt o-fzpibr'})\n",
        "    price=container.findAll('span', {'class':'o-eZTujG o-byFsZJ o-bkmzIL o-bVSleT'})\n",
        "    product_name = title_container[0].text\n",
        "    a.append(product_name)\n",
        "    abc=price[0].text\n",
        "    b.append(abc)\n",
        "    # print(product_name,'.....',abc)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(list(zip(a,b)), columns=['Product_name', 'price'])\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CODrhMymPhhX",
        "outputId": "913eebd8-3227-4225-f48f-4bfcf8507535"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Product_name        price\n",
            "0                        Lectrix LXS     ₹ 91,253\n",
            "1                     Ather 450 Apex   ₹ 1,89,021\n",
            "2                Kawasaki Eliminator   ₹ 5,62,000\n",
            "3               Kawasaki Ninja ZX-6R  ₹ 11,09,000\n",
            "4           Royal Enfield Hunter 350   ₹ 1,49,900\n",
            "5                     TVS Raider 125     ₹ 97,054\n",
            "6                    Yamaha MT 15 V2   ₹ 1,68,708\n",
            "7                     Aprilia RS 457   ₹ 4,10,007\n",
            "8                       Honda SP 125     ₹ 86,747\n",
            "9                      Yamaha R15 V4   ₹ 1,82,856\n",
            "10          Royal Enfield Bullet 350   ₹ 1,73,562\n",
            "11                TVS Apache RTR 160   ₹ 1,19,981\n",
            "12                   Honda Activa 6G     ₹ 77,710\n",
            "13         Royal Enfield Classic 350   ₹ 1,93,080\n",
            "14              Harley-Davidson X440   ₹ 2,39,500\n",
            "15  Royal Enfield Continental GT 650   ₹ 3,18,417\n",
            "16               Bajaj Pulsar RS 200   ₹ 1,71,783\n",
            "17                    Jawa 42 Bobber   ₹ 2,27,461\n",
            "18                TVS Apache RTR 310   ₹ 2,42,990\n",
            "19                Bajaj Pulsar NS125   ₹ 1,04,896\n",
            "20                Bajaj Pulsar NS200   ₹ 1,42,055\n",
            "21                     TVS Ntorq 125     ₹ 87,133\n",
            "22           Hero Splendor Plus Xtec     ₹ 79,703\n",
            "23                       Honda Shine     ₹ 80,404\n",
            "24                      KTM 200 Duke   ₹ 1,96,758\n",
            "25                         TVS Ronin   ₹ 1,49,195\n",
            "26          Royal Enfield Meteor 350   ₹ 2,05,826\n",
            "27       Royal Enfield Himalayan 450   ₹ 2,85,000\n",
            "28                 Bajaj Pulsar N160   ₹ 1,22,974\n",
            "29                      Yamaha FZ FI   ₹ 1,16,130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "my_url = 'https://bali.com/'\n",
        "page=requests.get(my_url)\n",
        "# print(page) #gives status response\n",
        "\n",
        "a=BeautifulSoup(page.text,'html')\n",
        "# print(a)\n",
        "# print(a.prettify()[:1000]) # gives in proper format\n",
        "\n",
        "#to get all links\n",
        "# count=0\n",
        "# for i in a.find_all('a'):\n",
        "#   print(i.get('href'))\n",
        "#   count+=1\n",
        "#   if count==20:\n",
        "#     break\n",
        "\n",
        "\n",
        "# a.get_text() #gives the text\n",
        "\n",
        "# import regex as re\n",
        "# for i in a.find_all('a',attrs={'href':re.compile(\"^http\")}):\n",
        "#   print(i)\n",
        "\n",
        "# file=open('abc.txt','w')\n",
        "# for i in a.find_all('p'):\n",
        "#   x=i.get_text()\n",
        "#   file.write(x)\n",
        "# file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rAgGcl1b_akO"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}